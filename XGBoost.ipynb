{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5878ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import asarray\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b71677",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Data preprocessing is the first step towards training any model. Here training data is loaded and alongwith oil prices data. Both the dataframes are merged on the date column in order to get a dataframe which contains all the predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b56b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"time_series_dataset/train/train.csv\")\n",
    "df=df.sort_values(['store_nbr','family'])\n",
    "\n",
    "df_oil = pd.read_csv(\"time_series_dataset/oil.csv\")\n",
    "filtered_oil_values=np.where((df_oil['date']>='2013-01-01') & (df_oil['date']<='2017-08-15'))\n",
    "df_oil = df_oil.loc[filtered_oil_values]\n",
    "\n",
    "df=pd.merge(df, df_oil, left_on='date', right_on='date',how=\"left\")\n",
    "\n",
    "oil_mean_price = df['dcoilwtico'].mean()\n",
    "df['dcoilwtico'] = df['dcoilwtico'].fillna(oil_mean_price)\n",
    "df = df[[\"id\",\"date\",\"store_nbr\",\"family\",\"onpromotion\",\"dcoilwtico\",\"sales\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f7c97f",
   "metadata": {},
   "source": [
    "This step is also the part of data preprocessing, where sales for each product family and store are shifted by one day so that these values become the sales for previous day and stored in the sales column and the target value for sales are stored in sales_pred column in the dataframe. This step is also the part of data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba543ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_list = []\n",
    "new_sales_list = []\n",
    "store_nbr_list = df['store_nbr'].unique()\n",
    "family_list = df['family'].unique()\n",
    "for i in store_nbr_list:\n",
    "    print(\"Store number : \",i)\n",
    "    for j in family_list:\n",
    "        temp_df_values = np.where((df['store_nbr']==i) & (df['family']==j))\n",
    "        temp_df = df.loc[temp_df_values]\n",
    "        temp_sales_list = temp_df['sales'].to_list()\n",
    "        new_temp_sales_list = []\n",
    "        new_temp_sales_list.append(0.0)\n",
    "        new_temp_sales_list.extend(temp_sales_list)\n",
    "        new_temp_sales_list = new_temp_sales_list[:-1]\n",
    "        new_sales_list.extend(new_temp_sales_list)\n",
    "        sales_list.extend(temp_sales_list)\n",
    "\n",
    "df[\"sales\"]=new_sales_list\n",
    "df[\"sales_pred\"]=sales_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9361a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this step product family is encoded using label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "family = df['family'].unique()\n",
    "le.fit(family)\n",
    "list(le.classes_)\n",
    "family_encoder = le.transform(df['family'])\n",
    "df['family'] = family_encoder\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8084d95",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7417df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df,family_id,scaler):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    df(pnadas dataframe): preprocessed pandas dataframe\n",
    "    family_id(int): id of product family for which the dataset needs to be created\n",
    "    scaler(sklearn object): the scale which will be used to transform the dataset\n",
    "    \n",
    "    Description: This function takes the preprocessed dataframe to split and transform the input dataframe into training\n",
    "    and testing dataframe.\n",
    "    \n",
    "    Return(tuple): a tuple of training and testing dataframe objects \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    temp_df_values = np.where(df['family']==family_id)\n",
    "    temp_df = df.loc[temp_df_values]\n",
    "    new_df = temp_df.drop([\"id\",\"date\",'family'], axis =1)\n",
    "\n",
    "    train_df, test_df = train_test_split(new_df, test_size=0.2)\n",
    "    \n",
    "    train_df = pd.DataFrame(scaler.fit_transform(train_df), columns=train_df.columns)\n",
    "    test_df = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)\n",
    "    \n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f63a5c",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_hat, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    y_hat(numpy array): actual values array\n",
    "    y(numpy array): predicted values array\n",
    "    \n",
    "    Description: Loss Funstion which Compute Root Mean Squared Logarithmic Error during testing\n",
    "    \n",
    "    Return(float): computed RMSLE value \n",
    "    \n",
    "    \"\"\"\n",
    "    metric = np.sqrt(sum((np.array(list(map(lambda x : np.log(x + 1), y_hat)))\n",
    "                         - np.array(list(map(lambda x : np.log(x + 1), y))))**2)/len(y))\n",
    "                \n",
    "    return round(metric, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e453202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_train_model(train,family_id):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    train(pnadas dataframe): transformed pandas dataframe for training the model\n",
    "    family_id(int): id of product family for which the model needs to be trained\n",
    "    \n",
    "    Description: This function takes the input tarining dataframe and trains a XGBoost model for input product family.\n",
    "    \n",
    "    Return(xgboost model object): trained model for a particular family  \n",
    "    \n",
    "    \"\"\"    \n",
    "    # transform dataframe into array\n",
    "    train = asarray(train)\n",
    "\n",
    "    # split into input and output columns\n",
    "    trainX, trainy = train[:, :-1], train[:, -1]\n",
    "    \n",
    "    # fit model\n",
    "    model = XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n",
    "    model.fit(trainX, trainy)\n",
    "    \n",
    "    #save model\n",
    "    model.save_model('./trained_XGB_models/family_'+str(family_id)+'_model.bin')\n",
    "    print('family_'+str(family_id)+' model trained')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7fa6d",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ad8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_test_model(test,model,scaler,family_id):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    test(pnadas dataframe): transformed pandas dataframe for testing the model\n",
    "    model(keras object): trained model object for a pariticular product family\n",
    "    scaler(sklearn object): the scale which will be used to transform the dataset\n",
    "    family_id(int): id of product family for which the model needs to be tested\n",
    "    \n",
    "    Description: This function takes the input testing dataframe and related parameters such as trained model, sclaer object\n",
    "    and test a XGBoost model for each product family against the unseen data.\n",
    "    \n",
    "    Return(float): RMSLE value for a particular product family  \n",
    "    \n",
    "    \"\"\"  \n",
    "    #break the dataframe into predictors arrays\n",
    "    test_X=asarray(test)[:,:-1]\n",
    "    \n",
    "    #predict the values using model\n",
    "    y_hat = model.predict(test_X)\n",
    "    \n",
    "    # transform the scaled dataframe\n",
    "    y_hat=y_hat.reshape(y_hat.shape[0],1)\n",
    "    inv_yhat = concatenate((test_X,y_hat), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_y = scaler.inverse_transform(test)\n",
    "    inv_yhat = inv_yhat[:,-1]\n",
    "    inv_yhat[inv_yhat < 0] = 0.0\n",
    "    inv_y = inv_y[:,-1]\n",
    "    \n",
    "    #plot the test curve\n",
    "    pyplot.figure(figsize=(15,5))\n",
    "    pyplot.plot(inv_y[:200], label='actual sales')\n",
    "    pyplot.plot(inv_yhat[:200], label='forecasted sales')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig('./trained_XGB_models/family_'+str(family_id)+'_forecasted_sales.png')\n",
    "    pyplot.show()\n",
    "\n",
    "    #compute RMSLE value\n",
    "    rmsle_value = rmsle(inv_yhat,inv_y)\n",
    "    return rmsle_value\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6cc98",
   "metadata": {},
   "source": [
    "# Driver Code/ Model Pipeline\n",
    "\n",
    "After preprocessing the dataset, the code can be used to train the model for each product family and saves the rmsle value for each product family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc71403",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "family_list = df['family'].unique()\n",
    "\n",
    "rmsle_dict = {}\n",
    "for i in family_list:\n",
    "    train_df,test_df=create_dataset(df,i,scaler)\n",
    "    model=xgboost_train_model(train_df,i)\n",
    "    rmsle_value=xgboost_test_model(test_df,model,scaler,i)\n",
    "    print(\"family_id_\"+str(i)+\": rmsle_value---- \",rmsle_value)\n",
    "    rmsle_dict[i]=rmsle_value\n",
    "    \n",
    "rmsle_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd6dc0f",
   "metadata": {},
   "source": [
    "# Test Dataset Preprocessing\n",
    "The test.csv is loaded and preprocessed same way as training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a8b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"time_series_dataset/test.csv\")\n",
    "test_df=test_df.sort_values(['store_nbr','family'])\n",
    "df_oil = pd.read_csv(\"time_series_dataset/oil.csv\")\n",
    "test_df=pd.merge(test_df, df_oil, left_on='date', right_on='date',how=\"left\")\n",
    "oil_mean_price = test_df['dcoilwtico'].mean()\n",
    "test_df['dcoilwtico'] = test_df['dcoilwtico'].fillna(oil_mean_price)\n",
    "test_family_encoder = le.transform(test_df['family'])\n",
    "test_df['family'] = test_family_encoder\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf134d9",
   "metadata": {},
   "source": [
    "# Test Dataset Prediction\n",
    "\n",
    "After preprocessing the test dataset, the model predictions are made for each family by loading the saved model and previous day sales are taken from the last day in the traing dataset and then predictions are transferred to the next day which act as previous day sales for next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "family_list = df['family'].unique()\n",
    "test_df_date_list = test_df['date'].to_list()\n",
    "test_df_date_list=list(set(test_df_date_list))\n",
    "test_df_date_list.sort()\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for j in family_list:\n",
    "    \n",
    "    # loading the sales values of last day for each family\n",
    "    filtered_df = np.where((df['date']=='2017-08-15') & (df['family']==j))\n",
    "    filtered_df = df.loc[filtered_df]\n",
    "    filtered_df = filtered_df.sort_values(['store_nbr','family'])\n",
    "    previous_day_sales = filtered_df['sales_pred'].to_list()\n",
    "    \n",
    "    # load the saved model\n",
    "    filename='./trained_XGB_models/family_'+str(family_list[j])+'_model.bin'\n",
    "    model = XGBRegressor()\n",
    "    model.load_model(filename)\n",
    "    \n",
    "    for i in test_df_date_list:\n",
    "        \n",
    "        # filtering the dataset for each date for particular family\n",
    "        input_df = np.where((test_df['date']==i) & (test_df['family']==j))\n",
    "        input_df = test_df.loc[input_df]\n",
    "        input_df['sales']= previous_day_sales\n",
    "        id_list = input_df[\"id\"].to_list()\n",
    "        date_list = input_df[\"date\"].to_list()\n",
    "        family_list = input_df[\"family\"].to_list()\n",
    "        input_df = input_df.drop([\"id\",\"date\",\"family\"], axis =1)\n",
    "        \n",
    "        # tranform the dataset\n",
    "        test_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        input_df = pd.DataFrame(test_scaler.fit_transform(input_df), columns=input_df.columns)\n",
    "        input_df_X=asarray(input_df)\n",
    "        \n",
    "        # predict the sales\n",
    "        test_yhat = model.predict(input_df_X)\n",
    "        test_yhat=test_yhat.reshape(test_yhat.shape[0],1)\n",
    "        inv_test_yhat = concatenate((input_df_X[:, :-1],test_yhat), axis=1)\n",
    "        inv_test_yhat = test_scaler.inverse_transform(inv_test_yhat)\n",
    "        inv_yhat = inv_test_yhat[:,-1]\n",
    "        inv_yhat[inv_yhat < 0] = 0.0\n",
    "        inv_test_yhat[:,-1]=inv_yhat\n",
    "        \n",
    "        #store the results in dataframe\n",
    "        forecasted_sales_df=pd.DataFrame(inv_test_yhat,columns=['store_nbr','onpromotion','dcoilwtico','sales_forecasted'])\n",
    "        forecasted_sales_df['id']=id_list\n",
    "        forecasted_sales_df['date']=date_list\n",
    "        forecasted_sales_df['family']=family_list\n",
    "        final_df = final_df.append(forecasted_sales_df, ignore_index=True)\n",
    "        previous_day_sales = forecasted_sales_df['sales_forecasted'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dee936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results to csv\n",
    "final_df = final_df[[\"id\", \"date\",\"store_nbr\", \"family\", \"onpromotion\", \"dcoilwtico\", \"sales_forecasted\"]]\n",
    "final_df['family']=le.inverse_transform(final_df['family'])\n",
    "final_df.to_csv('XGBoost_submission.csv')\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
