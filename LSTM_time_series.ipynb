{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3595155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db16d8",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Data preprocessing is the first step towards training any model. Here training data is loaded and alongwith oil prices data. Both the dataframes are merged on the date column in order to get a dataframe which contains all the predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca11d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"time_series_dataset/train/train.csv\")\n",
    "df=df.sort_values(['store_nbr','family'])\n",
    "\n",
    "df_oil = pd.read_csv(\"time_series_dataset/oil.csv\")\n",
    "filtered_oil_values=np.where((df_oil['date']>='2013-01-01') & (df_oil['date']<='2017-08-15'))\n",
    "df_oil = df_oil.loc[filtered_oil_values]\n",
    "\n",
    "df=pd.merge(df, df_oil, left_on='date', right_on='date',how=\"left\")\n",
    "\n",
    "oil_mean_price = df['dcoilwtico'].mean()\n",
    "df['dcoilwtico'] = df['dcoilwtico'].fillna(oil_mean_price)\n",
    "df = df[[\"id\",\"date\",\"store_nbr\",\"family\",\"onpromotion\",\"dcoilwtico\",\"sales\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d663467",
   "metadata": {},
   "source": [
    "This step is also the part of data preprocessing, where sales for each product family and store are shifted by one day so that these values become the sales for previous day and stored in the sales column and the target value for sales are stored in sales_pred column in the dataframe. This step is also the part of data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_list = []\n",
    "new_sales_list = []\n",
    "store_nbr_list = df['store_nbr'].unique()\n",
    "family_list = df['family'].unique()\n",
    "for i in store_nbr_list:\n",
    "    print(\"Store number : \",i)\n",
    "    for j in family_list:\n",
    "        temp_df_values = np.where((df['store_nbr']==i) & (df['family']==j))\n",
    "        temp_df = df.loc[temp_df_values]\n",
    "        temp_sales_list = temp_df['sales'].to_list()\n",
    "        new_temp_sales_list = []\n",
    "        new_temp_sales_list.append(0.0)\n",
    "        new_temp_sales_list.extend(temp_sales_list)\n",
    "        new_temp_sales_list = new_temp_sales_list[:-1]\n",
    "        new_sales_list.extend(new_temp_sales_list)\n",
    "        sales_list.extend(temp_sales_list)\n",
    "#         print(len(new_sales_list))\n",
    "df[\"sales\"]=new_sales_list\n",
    "df[\"sales_pred\"]=sales_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3377984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this step product family is encoded using label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "family = df['family'].unique()\n",
    "le.fit(family)\n",
    "list(le.classes_)\n",
    "family_encoder = le.transform(df['family'])\n",
    "df['family'] = family_encoder\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023cd57f",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e24af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(df,family_id,scaler):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    df(pnadas dataframe): preprocessed pandas dataframe\n",
    "    family_id(int): id of product family for which the dataset needs to be created\n",
    "    scaler(sklearn object): the scale which will be used to transform the dataset\n",
    "    \n",
    "    Description: This function takes the preprocessed dataframe to split and transform the input dataframe into training,\n",
    "    validation and testing dataframe.\n",
    "    \n",
    "    Return(tuple): a tuple of training, validation and testing dataframe objects \n",
    "    \n",
    "    \"\"\"\n",
    "    temp_df_values = np.where(df['family']==family_id)\n",
    "    temp_df = df.loc[temp_df_values]\n",
    "    new_df = temp_df.drop([\"id\",\"date\",'family'], axis =1)\n",
    "    \n",
    "    train_df, test_df = train_test_split(new_df, test_size=0.1)\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "    \n",
    "    train_df = pd.DataFrame(scaler.fit_transform(train_df), columns=train_df.columns)\n",
    "    val_df = pd.DataFrame(scaler.transform(val_df), columns=val_df.columns)\n",
    "    test_df = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)\n",
    "    \n",
    "    return train_df,val_df,test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbe794",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec0866",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def root_mean_squared_log_error(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    y_true(tensor object): actual values tensor\n",
    "    y_pred(tensor object): predicted values tensor\n",
    "    \n",
    "    Description: Custom loss function which Compute Root Mean Squared Logarithmic Error for model during training\n",
    "    \n",
    "    Return(float): computed RMSLE value \n",
    "    \n",
    "    \"\"\"\n",
    "    return K.sqrt(K.mean(K.square(K.log(1+y_pred) - K.log(1+y_true))))\n",
    "\n",
    "def rmsle(y_hat, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    y_hat(numpy array): actual values array\n",
    "    y(numpy array): predicted values array\n",
    "    \n",
    "    Description: Loss Funstion which Compute Root Mean Squared Logarithmic Error during testing\n",
    "    \n",
    "    Return(float): computed RMSLE value \n",
    "    \n",
    "    \"\"\"\n",
    "    metric = np.sqrt(sum((np.array(list(map(lambda x : np.log(x + 1), y_hat)))\n",
    "                         - np.array(list(map(lambda x : np.log(x + 1), y))))**2)/len(y))\n",
    "                \n",
    "    return round(metric, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df,val_df,learning_rate,epochs,family_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    train_df(pnadas dataframe): transformed pandas dataframe for training the model\n",
    "    val_df(pnadas dataframe): transformed pandas dataframe for validating the model\n",
    "    learning_rate(float): learning rate for the model to be trained\n",
    "    epochs(int): number of epochs for which the model needs to be trained\n",
    "    family_id(int): id of product family for which the model needs to be trained\n",
    "    \n",
    "    Description: This function takes the input tarining dataframe and realated parameters such as validation datafraem,\n",
    "    learning rate, epochs and trains a LSTM model for each product family.\n",
    "    \n",
    "    Return(keras model object): trained model for a particular family  \n",
    "    \n",
    "    \"\"\" \n",
    "    #break the datafraem into predictors and target arrays\n",
    "    train_X, train_y = train_df.values[:, :-1], train_df.values[:, -1]\n",
    "    val_X, val_y = val_df.values[:, :-1], val_df.values[:, -1]\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    val_X = val_X.reshape((val_X.shape[0], 1, val_X.shape[1]))\n",
    "\n",
    "    # setting seed value to get consistant results\n",
    "    np.random.seed(1234)\n",
    "    tf.random.set_seed(1234)\n",
    "\n",
    "    #complile the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    adm = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=root_mean_squared_log_error, optimizer=adm)\n",
    "    \n",
    "    # fit network and save model\n",
    "    history = model.fit(train_X, train_y, epochs=epochs, batch_size=256, validation_data=(val_X, val_y), verbose=2, shuffle=False)\n",
    "    model.save('./trained_models/family_'+str(family_id)+'_model.h5')\n",
    "    print('family_'+str(family_id)+' model trained')\n",
    "    \n",
    "    # plot history\n",
    "    pyplot.figure(figsize=(8,4))\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig('./trained_models/family_'+str(family_id)+'_loss_plot.png')\n",
    "    pyplot.show()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583922c0",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8395198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_df,model,scaler,family_id):\n",
    "\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    train_df(pnadas dataframe): transformed pandas dataframe for testing the model\n",
    "    model(keras object): trained model object for a pariticular product family\n",
    "    scaler(sklearn object): the scale which will be used to transform the dataset\n",
    "    family_id(int): id of product family for which the model needs to be tested\n",
    "    \n",
    "    Description: This function takes the input testing dataframe and related parameters such as trained model, sclaer object\n",
    "    and test a LSTM model for each product family against the unseen data.\n",
    "    \n",
    "    Return(float): RMSLE value for a particular product family  \n",
    "    \n",
    "    \"\"\" \n",
    "    #break the datafraem into predictors and target arrays\n",
    "    test_X, test_y = test_df.values[:, :-1], test_df.values[:, -1]\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "    #predict the values using model\n",
    "    yhat = model.predict(test_X)\n",
    "    yhat[yhat < 0] = 0.0\n",
    "    \n",
    "    # transform the scaled dataframe\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "    inv_yhat = concatenate((test_X[:, 0:],yhat), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,-1]\n",
    "    test_y = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = concatenate((test_X[:, 0:],test_y), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,-1]\n",
    "    \n",
    "    #compute RMSLE value\n",
    "    rmsle_value = rmsle(inv_yhat,inv_y)\n",
    "    print(\"RMSLE: %s\" %rmsle_value)\n",
    "    \n",
    "    #plot the test curve\n",
    "    pyplot.figure(figsize=(15,5))\n",
    "    pyplot.plot(inv_y[:200], label='actual sales')\n",
    "    pyplot.plot(inv_yhat[:200], label='forecasted sales')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig('./trained_models/family_'+str(family_id)+'_forecasted_sales.png')\n",
    "    pyplot.show()\n",
    "    \n",
    "    return rmsle_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092e3ed",
   "metadata": {},
   "source": [
    "# Driver Code/ Model Pipeline\n",
    "\n",
    "After preprocessing the dataset, the code can be used to train the model for each product family and training parameters like learning rate and epochs can be changed and saves the rmsle value for each product family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233eea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "family_list = df['family'].unique()\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "rmsle_dict = {}\n",
    "for i in family_list:\n",
    "    train_df,val_df,test_df=create_dataset(df,i,scaler)\n",
    "    model=train_model(train_df,val_df,learning_rate,epochs,i)\n",
    "    rmsle_value=test_model(test_df,model,scaler,i)\n",
    "    rmsle_dict[i]=rmsle_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsle_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53ee3f",
   "metadata": {},
   "source": [
    "# Test Dataset Preprocessing\n",
    "The test.csv is loaded and preprocessed same way as training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"time_series_dataset/test.csv\")\n",
    "test_df=test_df.sort_values(['store_nbr','family'])\n",
    "df_oil = pd.read_csv(\"time_series_dataset/oil.csv\")\n",
    "test_df=pd.merge(test_df, df_oil, left_on='date', right_on='date',how=\"left\")\n",
    "oil_mean_price = test_df['dcoilwtico'].mean()\n",
    "test_df['dcoilwtico'] = test_df['dcoilwtico'].fillna(oil_mean_price)\n",
    "test_family_encoder = le.transform(test_df['family'])\n",
    "test_df['family'] = test_family_encoder\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0cb5e0",
   "metadata": {},
   "source": [
    "# Test Dataset Prediction\n",
    "\n",
    "After preprocessing the test dataset, the model predictions are made for each family by loading the saved model and previous daya sales are taken from the last day in the traing dataset and then predictions are transferred to the next day which act as previous day sales for next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "family_list = df['family'].unique()\n",
    "test_df_date_list = test_df['date'].to_list()\n",
    "test_df_date_list=list(set(test_df_date_list))\n",
    "test_df_date_list.sort()\n",
    "final_df = pd.DataFrame()\n",
    "for j in family_list:\n",
    "    \n",
    "    # loading the sales values of last day for each family\n",
    "    filtered_df = np.where((df['date']=='2017-08-15') & (df['family']==j))\n",
    "    filtered_df = df.loc[filtered_df]\n",
    "    filtered_df = filtered_df.sort_values(['store_nbr','family'])\n",
    "    previous_day_sales = filtered_df['sales_pred'].to_list()\n",
    "    \n",
    "    # load the saved model\n",
    "    model = load_model('./trained_models/family_'+str(family_list[j])+'_model.h5',custom_objects={'root_mean_squared_log_error': root_mean_squared_log_error})\n",
    "    \n",
    "    for i in test_df_date_list:\n",
    "        \n",
    "        # filtering the dataset for each date for particular family\n",
    "        input_df = np.where((test_df['date']==i) & (test_df['family']==j))\n",
    "        input_df = test_df.loc[input_df]\n",
    "        input_df = input_df.sort_values(['store_nbr'])\n",
    "        input_df['sales']= previous_day_sales\n",
    "        id_list = input_df[\"id\"].to_list()\n",
    "        date_list = input_df[\"date\"].to_list()\n",
    "        family_list = input_df[\"family\"].to_list()\n",
    "        input_df = input_df.drop([\"id\",\"date\",\"family\"], axis =1)\n",
    "        \n",
    "        # tranform the dataset\n",
    "        test_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        input_df = pd.DataFrame(test_scaler.fit_transform(input_df), columns=input_df.columns)\n",
    "        input_df_X = input_df.values.reshape((input_df.values.shape[0], 1, input_df.values.shape[1]))\n",
    "        \n",
    "        # predict the sales\n",
    "        test_yhat = model.predict(input_df_X)\n",
    "        test_yhat[test_yhat < 0] = 0.0\n",
    "        input_df_X = input_df_X.reshape((input_df_X.shape[0], input_df_X.shape[2]))\n",
    "        inv_test_yhat = concatenate((input_df_X[:, :-1],test_yhat), axis=1)\n",
    "        inv_test_yhat = test_scaler.inverse_transform(inv_test_yhat)\n",
    "        \n",
    "        #store the results in dataframe\n",
    "        forecasted_sales_df=pd.DataFrame(inv_test_yhat,columns=['store_nbr','onpromotion','dcoilwtico','sales_forecasted'])\n",
    "        forecasted_sales_df['id']=id_list\n",
    "        forecasted_sales_df['date']=date_list\n",
    "        forecasted_sales_df['family']=family_list\n",
    "        final_df = final_df.append(forecasted_sales_df, ignore_index=True)\n",
    "        previous_day_sales = forecasted_sales_df['sales_forecasted'].to_list()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results to csv\n",
    "final_df = final_df[[\"id\", \"date\",\"store_nbr\", \"family\", \"onpromotion\", \"dcoilwtico\", \"sales_forecasted\"]]\n",
    "final_df['family']=le.inverse_transform(final_df['family'])\n",
    "final_df.to_csv('submission.csv')\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
